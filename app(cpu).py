# file: app.py (phiÃªn báº£n TensorFlow + YoloV5FaceDetector)
import gradio as gr
import numpy as np
import cv2
import os
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import normalize
from tqdm import tqdm
import faiss

# Import lá»›p YoloV5FaceDetector tá»« file cá»§a báº¡n
from face_detector import YoloV5FaceDetector

# --- Cáº¤U HÃŒNH VÃ€ BIáº¾N TOÃ€N Cá»¤C ---
script_dir = os.path.dirname(os.path.abspath(__file__))

# ÄÆ°á»ng dáº«n tá»›i cÃ¡c tÃ i nguyÃªn
RECOGNIZER_MODEL_PATH = os.path.join(script_dir, "data/GhostFaceNet_W1.3_S1_ArcFace.h5")
INITIAL_DATA_CSV = os.path.join(script_dir, "data/data_new/data.csv")
INITIAL_IMAGE_ROOT = os.path.join(script_dir, "data/data_new/images")
UPLOAD_DIR = os.path.join(script_dir, "uploads")

if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)

# --- KHá»I Táº O CÃC MODEL ---

# 1. Khá»Ÿi táº¡o YoloV5FaceDetector
# Lá»›p nÃ y sáº½ tá»± Ä‘á»™ng táº£i model yolov5s_face_dynamic.h5 náº¿u khÃ´ng tÃ¬m tháº¥y
print("Äang táº£i model Face Detector (YOLOv5)...")
detector = YoloV5FaceDetector()
print("Táº£i Face Detector thÃ nh cÃ´ng!")

# 2. Khá»Ÿi táº¡o model nháº­n dáº¡ng GhostFaceNet
try:
    print("Äang táº£i model Face Recognizer (GhostFaceNet)...")
    recognizer_model = tf.keras.models.load_model(RECOGNIZER_MODEL_PATH, compile=False)
    # Táº¡o interface Ä‘á»ƒ trÃ­ch xuáº¥t embedding
    model_interf = lambda imms: recognizer_model((imms - 127.5) * 0.0078125, training=False).numpy()
    print("Táº£i Face Recognizer thÃ nh cÃ´ng!")
except Exception as e:
    print(f"Lá»—i: KhÃ´ng thá»ƒ táº£i model táº¡i '{RECOGNIZER_MODEL_PATH}'. Lá»—i: {e}")
    exit()

# 3. Kiá»ƒm tra Faiss GPU
try:
    FAISS_USE_GPU = faiss.get_num_gpus() > 0
    if FAISS_USE_GPU: print(f"Faiss: ÄÃ£ tÃ¬m tháº¥y {faiss.get_num_gpus()} GPU. Sáº½ sá»­ dá»¥ng GPU.")
    else: print("Faiss: KhÃ´ng tÃ¬m tháº¥y GPU, sáº½ sá»­ dá»¥ng CPU.")
except AttributeError:
    FAISS_USE_GPU = False; print("Faiss: PhiÃªn báº£n faiss-cpu Ä‘Æ°á»£c cÃ i Ä‘áº·t, sáº½ sá»­ dá»¥ng CPU.")

# Biáº¿n toÃ n cá»¥c
db_data = {"all_embs": None, "all_classes": None}
user_data = {}
faiss_index = None
next_user_id = 0
faiss_id_map = []

# --- CÃC HÃ€M Xá»¬ LÃ CHUáº¨N ---

def detect_and_get_embedding(image_np):
    """
    Quy trÃ¬nh chuáº©n: DÃ¹ng YOLO Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  cÄƒn chá»‰nh, sau Ä‘Ã³ dÃ¹ng GhostFaceNet Ä‘á»ƒ embedding.
    """
    # 1. PhÃ¡t hiá»‡n vÃ  cÄƒn chá»‰nh khuÃ´n máº·t báº±ng YoloV5FaceDetector
    # image_np cáº§n á»Ÿ Ä‘á»‹nh dáº¡ng RGB
    image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)
    _, _, _, aligned_faces = detector.detect_in_image(image_rgb)
    
    if aligned_faces.shape[0] == 0:
        print("Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t trong áº£nh.")
        return None

    # Láº¥y khuÃ´n máº·t Ä‘áº§u tiÃªn (Ä‘Ã£ Ä‘Æ°á»£c cÄƒn chá»‰nh vÃ  resize vá» 112x112)
    face_112x112 = aligned_faces[0]
    
    # 2. TrÃ­ch xuáº¥t embedding tá»« khuÃ´n máº·t Ä‘Ã£ cÄƒn chá»‰nh
    face_expanded = np.expand_dims(face_112x112, axis=0)
    emb = model_interf(face_expanded)
    
    return normalize(emb.astype("float32"))[0]

# CÃ¡c hÃ m logic chÃ­nh (initialize, update_faiss, register, login)
# sáº½ gá»i hÃ m `detect_and_get_embedding` má»›i nÃ y. Code cá»§a chÃºng khÃ´ng thay Ä‘á»•i nhiá»u.
def update_faiss_index():
    """
    TÃ­nh toÃ¡n láº¡i cÃ¡c vector Ä‘áº¡i diá»‡n tá»« Ä‘áº§u vÃ  cáº­p nháº­t index Faiss.
    Tá»± Ä‘á»™ng sá»­ dá»¥ng GPU náº¿u cÃ³.
    """
    global faiss_index, faiss_id_map
    print("Äang cáº­p nháº­t láº¡i Faiss index...")

    # 1. Láº¥y táº¥t cáº£ cÃ¡c ID Ä‘Ã£ cÃ³ (cáº£ gá»‘c vÃ  má»›i) vÃ  táº¡o map
    all_known_ids = []
    if db_data["all_classes"] is not None:
        all_known_ids = np.unique(db_data["all_classes"]).tolist()
    all_known_ids.extend(list(user_data.keys()))
    faiss_id_map = sorted(list(set(all_known_ids))) # Map tá»« index cá»§a Faiss -> ID tháº­t

    if not faiss_id_map:
        print("KhÃ´ng cÃ³ ngÆ°á»i dÃ¹ng nÃ o Ä‘á»ƒ index.")
        faiss_index = None
        return

    # 2. TÃ­nh toÃ¡n vector Ä‘áº¡i diá»‡n
    representative_embs = []
    for identity_id in tqdm(faiss_id_map, desc="Táº¡o vector Ä‘áº¡i diá»‡n"):
        embs_for_user = []
        if identity_id in user_data: # LÃ  ngÆ°á»i dÃ¹ng má»›i
            image_paths = user_data[identity_id]
            for p in image_paths:
                emb = detect_and_get_embedding(cv2.imread(p))
                if emb is not None: embs_for_user.append(emb)
        else: # LÃ  ngÆ°á»i dÃ¹ng trong dataset gá»‘c
            indices = np.where(db_data["all_classes"] == identity_id)[0]
            embs_for_user = db_data["all_embs"][indices]
        
        # ----- DÃ’NG ÄÃƒ Sá»¬A Lá»–I -----
        if len(embs_for_user) == 0: continue
        # ---------------------------
        
        sum_emb = np.sum(embs_for_user, axis=0)
        rep_emb = normalize([sum_emb])[0]
        representative_embs.append(rep_emb)
    
    if not representative_embs:
        print("KhÃ´ng cÃ³ embedding há»£p lá»‡ Ä‘á»ƒ táº¡o index."); faiss_index = None; return
        
    # 3. XÃ¢y dá»±ng Faiss Index (GPU hoáº·c CPU)
    representative_embs_np = np.array(representative_embs).astype('float32')
    dimension = representative_embs_np.shape[1]

    if FAISS_USE_GPU:
        res = faiss.StandardGpuResources()
        cpu_index = faiss.IndexFlatIP(dimension)
        gpu_index = faiss.index_cpu_to_gpu(res, 0, cpu_index)
        faiss_index = gpu_index
    else:
        faiss_index = faiss.IndexFlatIP(dimension)

    faiss_index.add(representative_embs_np)
    print(f"Cáº­p nháº­t Faiss index thÃ nh cÃ´ng vá»›i {faiss_index.ntotal} ngÆ°á»i dÃ¹ng.")


def initialize_system():
    global db_data, next_user_id
    print("Äang khá»Ÿi táº¡o há»‡ thá»‘ng tá»« dataset ban Ä‘áº§u...")
    try:
        df = pd.read_csv(INITIAL_DATA_CSV)
    except FileNotFoundError:
        print(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file {INITIAL_DATA_CSV}. Bá» qua."); update_faiss_index(); return

    embs, classes = [], []
    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc="TrÃ­ch xuáº¥t embedding gá»‘c"):
        img_path = os.path.join(INITIAL_IMAGE_ROOT, row['image'])
        if os.path.exists(img_path):
            img = cv2.imread(img_path)
            emb = detect_and_get_embedding(img)
            if emb is not None:
                embs.append(emb)
                classes.append(row['label'])

    if embs:
        db_data["all_embs"] = np.array(embs)
        db_data["all_classes"] = np.array(classes)
        next_user_id = db_data["all_classes"].max() + 1
    else:
        next_user_id = 0
    update_faiss_index()
    print(f"Khá»Ÿi táº¡o hoÃ n táº¥t. ID tiáº¿p theo: {next_user_id}")


def register_face(img1, img2):
    global user_data, next_user_id
    if img1 is None or img2 is None:
        return "Lá»—i: Vui lÃ²ng táº£i lÃªn cáº£ hai áº£nh.", None

    if detect_and_get_embedding(img1) is None or detect_and_get_embedding(img2) is None:
        return "Lá»—i: KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t trong má»™t hoáº·c cáº£ hai áº£nh. Vui lÃ²ng thá»­ láº¡i vá»›i áº£nh khÃ¡c.", None

    registered_id = next_user_id
    img1_path = os.path.join(UPLOAD_DIR, f"{registered_id}_1.jpg"); cv2.imwrite(img1_path, cv2.cvtColor(img1, cv2.COLOR_RGB2BGR))
    img2_path = os.path.join(UPLOAD_DIR, f"{registered_id}_2.jpg"); cv2.imwrite(img2_path, cv2.cvtColor(img2, cv2.COLOR_RGB2BGR))
    
    user_data[registered_id] = [img1_path, img2_path]
    next_user_id += 1
    update_faiss_index()
    
    return f" ÄÄƒng kÃ½ thÃ nh cÃ´ng! ID cá»§a báº¡n lÃ : {registered_id}", user_data[registered_id]


def login_face(login_img):
    if login_img is None: return "Lá»—i: Vui lÃ²ng táº£i áº£nh lÃªn.", None, None
    if faiss_index is None or faiss_index.ntotal == 0: return "Lá»—i: Há»‡ thá»‘ng chÆ°a cÃ³ ngÆ°á»i dÃ¹ng.", None, None

    login_emb = detect_and_get_embedding(login_img)
    if login_emb is None:
        return " KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c: khÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t trong áº£nh Ä‘Äƒng nháº­p.", None, None
    
    login_emb_np = np.expand_dims(login_emb.astype('float32'), axis=0)
    D, I = faiss_index.search(login_emb_np, 1)
    faiss_match_index = I[0][0]; best_match_score = D[0][0]
    matched_id_in_db = faiss_id_map[faiss_match_index]
    
    print(f"Faiss search: ID gáº§n nháº¥t {matched_id_in_db} vá»›i Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng {best_match_score:.4f}")
    
    threshold = 0.5
    
    if best_match_score < threshold:
        return f" KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c. (Score: {best_match_score:.4f} < {threshold})", login_img, None
    else:
        if matched_id_in_db in user_data:
            gallery_output = user_data.get(matched_id_in_db, [])
        else:
            df = pd.read_csv(INITIAL_DATA_CSV)
            image_files = df[df['label'] == matched_id_in_db]['image'].tolist()
            gallery_output = [os.path.join(INITIAL_IMAGE_ROOT, fname) for fname in image_files]
            
        message = f" ÄÄƒng nháº­p thÃ nh cÃ´ng! Nháº­n dáº¡ng lÃ  ngÆ°á»i dÃ¹ng cÃ³ ID: {matched_id_in_db} (Score: {best_match_score:.4f})"
        return message, login_img, gallery_output

# --- GIAO DIá»†N GRADIO ---
with gr.Blocks(theme=gr.themes.Soft(), title="Há»‡ thá»‘ng Nháº­n dáº¡ng KhuÃ´n máº·t") as demo:
    gr.Markdown("# á»¨ng dá»¥ng Nháº­n dáº¡ng KhuÃ´n máº·t (TensorFlow + YOLOv5 Detector)")
    gr.Markdown("Quy trÃ¬nh chuáº©n: **PhÃ¡t hiá»‡n khuÃ´n máº·t báº±ng YOLOv5** -> TrÃ­ch xuáº¥t Embedding -> Nháº­n dáº¡ng.")
    
    with gr.Tabs():
        # Giao diá»‡n khÃ´ng thay Ä‘á»•i
        with gr.TabItem(" ÄÄƒng kÃ½"):
            gr.Markdown("## ÄÄƒng kÃ½ ngÆ°á»i dÃ¹ng má»›i"); gr.Markdown("Táº£i lÃªn 2 áº£nh chÃ¢n dung rÃµ nÃ©t cá»§a báº¡n Ä‘á»ƒ há»‡ thá»‘ng há»c.")
            with gr.Row():
                img_reg_1 = gr.Image(label="áº¢nh 1", type="numpy", height=224, width=224)
                img_reg_2 = gr.Image(label="áº¢nh 2", type="numpy", height=224, width=224)
            btn_register = gr.Button("ğŸš€ Báº¯t Ä‘áº§u ÄÄƒng kÃ½", variant="primary")
            output_register_status = gr.Textbox(label="Tráº¡ng thÃ¡i", interactive=False)
            output_register_gallery = gr.Gallery(label="áº¢nh Ä‘Ã£ Ä‘Äƒng kÃ½", object_fit="contain", height="auto")

        with gr.TabItem(" ÄÄƒng nháº­p"):
            gr.Markdown("## ÄÄƒng nháº­p vÃ o há»‡ thá»‘ng"); gr.Markdown("Táº£i lÃªn 1 áº£nh cá»§a báº¡n Ä‘á»ƒ xÃ¡c thá»±c.")
            img_login = gr.Image(label="áº¢nh ÄÄƒng nháº­p", type="numpy", height=224, width=224)
            btn_login = gr.Button("ğŸ›°ï¸ ÄÄƒng nháº­p", variant="primary")
            output_login_status = gr.Textbox(label="Káº¿t quáº£ Nháº­n dáº¡ng", interactive=False)
            with gr.Row():
                output_query_img = gr.Image(label="áº¢nh báº¡n Ä‘Ã£ dÃ¹ng Ä‘á»ƒ Ä‘Äƒng nháº­p", type="numpy", height=224, width=224)
                output_login_gallery = gr.Gallery(label="áº¢nh cá»§a ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c nháº­n dáº¡ng", object_fit="contain", height="224")

    btn_register.click(fn=register_face, inputs=[img_reg_1, img_reg_2], outputs=[output_register_status, output_register_gallery])
    btn_login.click(fn=login_face, inputs=[img_login], outputs=[output_login_status, output_query_img, output_login_gallery])

if __name__ == "__main__":
    initialize_system()
    demo.launch(debug=True)